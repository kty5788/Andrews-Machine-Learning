# Gradient Descent
머신러닝 9강
<pre>
J의 최솟값을 구하는 알고리즘에 대해 알아보겠다. 그것은 바로 '기울기 하강'
'기울기 하강'은 선형회귀에서만 사용되지 않고 머신러닝의 모든 부분에서 사용되고 있다.


J(θ0 , θ1)라는 함수가 있을 때 J(θ0 , θ1)의 최소화를 구하기를 원할 때

어떠한 수로 θ0 , θ1을 지정해놓고
J(θ0 , θ1)이 최소가 될 때까지 θ0, θ1의 값을 바꾸는 식으로 최소화 할 것이다.

이 함수를 최소화할려고 한다.
<img width="675" alt="스크린샷 2021-10-17 오후 5 00 42" src="https://user-images.githubusercontent.com/63940620/137617737-f225645c-3837-4d2f-b9ed-540ad0baae25.png">

최소화를 구할 때 θ0 , θ1을 어떠한 지점으로 설정한다면 아래의 그림처럼 그려질 것이다.
<img width="717" alt="스크린샷 2021-10-17 오후 5 02 30" src="https://user-images.githubusercontent.com/63940620/137617804-16b24ae7-e8cb-456c-88c6-84e196ad4c11.png">

비유를 조금 하자면, 언덕에서 가장 낮은 곳으로 이동 할 때 거리가 짧게 이동한다고 가정하자.

그러면 이러한 그림이 나온다.
<img width="698" alt="스크린샷 2021-10-17 오후 5 13 45" src="https://user-images.githubusercontent.com/63940620/137618102-c96925f9-b554-456d-b835-e113a40118df.png">

위의 이미지는 어느 한 지점에서 최솟값으로 이동하는 것이다.

하지만 시작지점이 다르다면 어떨까?
<img width="681" alt="스크린샷 2021-10-17 오후 5 20 10" src="https://user-images.githubusercontent.com/63940620/137618314-397d5add-d68c-4522-b555-4a6c4648c20e.png">

이 지점에서 가장 적은 걸음의 기울기의 최솟값으로 이동한다면 아래의 사진처럼 두 번째 '지역적 최솟값'을 가지게 된다.
<img width="723" alt="스크린샷 2021-10-17 오후 5 21 28" src="https://user-images.githubusercontent.com/63940620/137618353-f98696cb-261f-4db8-803e-8288c2598166.png">


이를 통해 시작 지점에 따라 다른 지역적 최솟값을 가질 수 있다는 것을 알 수 있다.
여기까지가 그래프에 대한 개념이다.
그러면 수학으로 가보자.

<img width="740" alt="스크린샷 2021-10-17 오후 5 31 17" src="https://user-images.githubusercontent.com/63940620/137618714-fb4da98d-0091-4cd0-9806-e92f18396858.png">

벌써 어지럽다. 일단 이해하기 위해 표현을 정리해보자

먼저 공식을 보다보면은 := 이라고 쓰여있는 것이 있을 것이다.
여기서 := 는 대입 하는 것을 의미한다. (C언어 = 라고 보면 된다)
만약 = 로 표기 하면 True or False를 가리는 참거짓이 되기 때문이다. ( 수학에서 = 는 C언어 == 라고 생각하면 편하다. )

여기서 a는 '학습 비율(Learning Rate)'로 이동 거리라고 생각하면 편하다.

a 뒤의 부분은 미분계수이다. (미분 계수는 지금 글에서는 설명하지 않겠다. / 일단 넘어가자)

주의사항
<img width="878" alt="스크린샷 2021-10-17 오후 5 54 21" src="https://user-images.githubusercontent.com/63940620/137619657-34a24b5f-629c-4b6c-a093-175c415beae7.png">

기울기 하강을 통해 최솟값을 구할 때 중간에 θ1과 θ2를 바꾸면 안된다. 중간에 값을 바꾸게 되면 (동시에 값을 바꾸지 않으면) θ0 or θ1이 다른 값이 들어간 상태로 계산해서
값이 이상하거나 오래 걸릴 수 있다. 오른쪽 그림처럼 중간에 바꾸는 알고리즘을 좋지 않다.

지금까지 기울기 하강에 대한 뼈대를 잡았다.

</pre>
<pre>
한줄정리)
  - '기울기 하강'에 대해 배웠고 '기울기 하강' 알고리즘을 어느정도 알아보았다.(다 배우지 않았음)
</pre>
