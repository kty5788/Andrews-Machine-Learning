# Cost Function - Intuition II
머신러닝 8강
<pre>

*** 이 부분은 이해를 했든 하지 않았든 원한다면 뛰어넘어도(skip)해도 된다. ***

이러한 데이터가 있다고 가정하자.

<img width="524" alt="스크린샷 2021-10-17 오후 2 23 32" src="https://user-images.githubusercontent.com/63940620/137613003-6da1ed2b-a2c2-46ee-a1bf-8d8f592be27c.png">

사진에 있는 일차함수는 좋은 가설이 아니다.
최적화 시킨 일차함수를 알아내기 위해서는 θ0 과 θ1에 적절한 값을 주어야 한다.

저번시간에는 θ1라는 변수 1개만을 가지고 비용함수를 그렸지만
이번에는 θ1 , θ2라는 변수 2개를 가지고 비용함수를 그릴 것이다. (전보다 더 복잡함)

변수 2개를 가지고 비용함수를 그리게 되면 아래와 같은 그림이 나온다.
<img width="651" alt="스크린샷 2021-10-17 오후 2 33 03" src="https://user-images.githubusercontent.com/63940620/137613263-089a82ac-9d52-4136-a3b0-87200655e01a.png">


이 그림처럼 3차원 형태로 되어있는 그래프를 '등고선 그래프' or '등고선 형태'라고 한다.

<img width="916" alt="스크린샷 2021-10-17 오후 2 42 28" src="https://user-images.githubusercontent.com/63940620/137613448-7783d01a-897f-4184-871c-2dfba2c3430f.png">

등고선 형태의 예시가 위 그림에 있다. (등고선 그래프의 낮은 부분은 파란색에 가깝게 , 높은 부분은 빨간색에 가깝다. , 색깔이 같으면 높이가 같다)


<img width="925" alt="스크린샷 2021-10-17 오후 2 47 43" src="https://user-images.githubusercontent.com/63940620/137613573-254ec9cc-6b24-45e9-824b-a93d06fa921e.png">

hθ(x)의 그래프에 있는 이 직선은 눈으로 봐도 일치하지 않다는 것을 알지만 값을 구한 후 J(θ0 , θ1)에 값을 넣어보면 등고선 그래프의 빨간색 X 부분에 위치한다.

<img width="930" alt="스크린샷 2021-10-17 오후 2 49 42" src="https://user-images.githubusercontent.com/63940620/137613625-eaa63615-26f8-4f33-bece-cf1b3ce330d4.png">

여기에 다른 가설이 있다. 이 가설도 데이터에 비슷하지는 않지만 전에 봤던 그래프 보다는 데이터에 비교적 일치하는 것을 알 수 있다.

<img width="906" alt="스크린샷 2021-10-17 오후 2 51 16" src="https://user-images.githubusercontent.com/63940620/137613645-5030224f-9bd7-4d10-b853-7cad6a5e7e88.png">

이 가설은 눈으로 보기에 최적화에 가까운 가설이라고 볼 수있다. 이 hθ(x)를 J(θ0 , θ1)에 위치 시켜보면 등고선 그래프의 가장 최하 부분과 가깝다는 것을 알 수 있다.

(파라메터(변수)가 θ0 , θ1 로 두 개일 때도 θ1 변수 하나만을 가지고 최적화를 구현했던 것 처럼 비용함수가 가장 작은 것을 최적화로 가진 다는 것을 알 수 있다.)
</pre>
<pre>
한줄 정리)
  - 변수가 2개일 때도 변수가 1개일 때와 같은 방식으로 최적화를 한다는 내용을 배웠다.
</pre>
